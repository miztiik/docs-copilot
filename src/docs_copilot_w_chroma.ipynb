{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docs Copilot â€“ A Generative AI App for Searching Documentation\n",
    "\n",
    "Github: https://github.com/miztiik/docs-copilot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT NEXT LINE TO SKIP THIS CELL EXECUTION\n",
    "# %%script skipping --no-raise-error\n",
    "\n",
    "# Install the dependencies for the project\n",
    "\n",
    "%pip install --quiet numpy\n",
    "%pip install --quiet openai\n",
    "%pip install --quiet python-dotenv\n",
    "%pip install --quiet tenacity\n",
    "%pip install --quiet tiktoken \n",
    "%pip install --quiet --upgrade chromadb \n",
    "%pip install --quiet langchain\n",
    "\n",
    "# For progress bar and process time\n",
    "%pip install --quiet tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Vector Embeddings store\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# For exponential backoff\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_OPENAI_ENDPOINT: https://eastus.api.cognitive.microsoft.com/\n",
      "AZURE_OPENAI_API_VERSION: 2023-05-15\n"
     ]
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "\n",
    "# specify the name of the .env file name\n",
    "# env_name = \"./env/docs_copilot.env\"\n",
    "# config = dotenv_values(env_name)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Raw Data Path\n",
    "RAW_DATA_PATH = \"./../data/raw/azure_docs/\"\n",
    "\n",
    "# DB_PATH = os.getenv(\"DB_PATH\")\n",
    "DB_PATH = \"./../data/processed/dbs/azure_docs/\"\n",
    "COLLECTION_NAME = \"fn_markdown\"\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "\n",
    "# Azure OpenAI Models\n",
    "embeddings_deployment_name = \"nice\"\n",
    "embeddings_deployment_model = \"text-embedding-ada-002\"\n",
    "completions_deployment_name = \"hellno\"\n",
    "completions_deployment_model = \"gpt-35-turbo-16k\"\n",
    "\n",
    "# Hugging Face Models\n",
    "hf_model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "print(f\"AZURE_OPENAI_API_VERSION: {os.getenv('AZURE_OPENAI_API_VERSION')}\")\n",
    "\n",
    "if AZURE_OPENAI_API_KEY is None:\n",
    "    print(\"Please set the AZURE_OPENAI_API_KEY environment variable\")\n",
    "    raise EnvironmentError(\"Please set the AZURE_OPENAI_API_KEY environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 15:40:45,328 - root - INFO - Welcome to Miztiik Automation for Docs Copilot\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.info(\"Welcome to Miztiik Automation for Docs Copilot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Hugging Face Embeddings & Test them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 15:42:05,211 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2024-01-21 15:42:05,498 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n",
      "2024-01-21 15:42:05,499 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2024-01-21 15:42:05,566 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refer Embedding Leaderboard: https://huggingface.co/spaces/mteb/leaderboard\n",
      "Refer Embedding Leaderboard: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598ff27c1f8e49398540c1ca95ec45f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 15:42:05,603 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-01-21 15:42:05,684 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n",
      "2024-01-21 15:42:05,703 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-01-21 15:42:05,777 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43eb4ab37cd4d48971eb383bfdeab6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated embeddings\n"
     ]
    }
   ],
   "source": [
    "sample_txt = [\"This is an Miztikal World\", \"Lets rejoice to together\"]\n",
    "\n",
    "# Inititalise the embedding\n",
    "embeddings_fn_by_hf = HuggingFaceEmbeddings()\n",
    "\n",
    "print(f\"Refer Embedding Leaderboard: https://huggingface.co/spaces/mteb/leaderboard\")\n",
    "print(\n",
    "    f\"Refer Embedding Leaderboard: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "hf_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "sample_txt_embeddings = hf_model.encode(sample_txt)\n",
    "\n",
    "if sample_txt_embeddings is None:\n",
    "    print(\"Unable to embedd the query\")\n",
    "\n",
    "embeddings_fn_by_hf = HuggingFaceEmbeddings(model_name=hf_model_name)\n",
    "\n",
    "# Inititalise the embedding fn for Chroma Document Level Embedding\n",
    "embeddings_fn_4_collections = SentenceTransformerEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "\n",
    "sample_txt_embeddings = embeddings_fn_by_hf.embed_query(sample_txt[0])\n",
    "\n",
    "if sample_txt_embeddings is None:\n",
    "    print(f\"Unable to embedd the query\")\n",
    "else:\n",
    "    print(f\"Successfully generated embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Vector Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chromadb(db_path):\n",
    "    if os.path.exists(db_path) and os.path.isdir(db_path):\n",
    "        print(\"Deleting existing ChromaDB at\", db_path)\n",
    "        shutil.rmtree(db_path)\n",
    "\n",
    "\n",
    "def write_to_vec_store_collection(\n",
    "    db_path, collection_name, docs_list, ids_list, embeddings_list, metadatas_list\n",
    "):\n",
    "    docs_vs_status = False\n",
    "    try:\n",
    "        vs_client = chromadb.PersistentClient(\n",
    "            path=db_path,\n",
    "        )\n",
    "        vs_collection = vs_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "        vs_collection.add(\n",
    "            documents=docs_list,\n",
    "            ids=ids_list,\n",
    "            embeddings=embeddings_list,\n",
    "            metadatas=metadatas_list,\n",
    "        )\n",
    "\n",
    "        vs_client = None\n",
    "        docs_vs_status = True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        raise e\n",
    "    return docs_vs_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Documents to ChromaDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Tokens in each document\n",
    "def count_tokens(model_name, docs):\n",
    "    token_count = 0\n",
    "    tokenizer = tiktoken.encoding_for_model(model_name)\n",
    "    token_count = [len(tokenizer.encode(d.page_content)) for d in docs]\n",
    "    print(token_count)\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    md_headers_to_split_on, strip_headers=False\n",
    ")\n",
    "\n",
    "chunk_size = 250\n",
    "chunk_overlap = 30\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    # length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\, )\", \" \", \"\", \"#\", \"##\", \"###\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize text splitter and embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "\n",
    "def get_files_with_extension(dir_path, doc_extension):\n",
    "    \"\"\"\n",
    "    Get a list of files in a directory (including subdirectories) matching a file extension.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(doc_extension):\n",
    "                files.append(os.path.join(dirpath, filename))\n",
    "    return files\n",
    "\n",
    "\n",
    "def ingest_docs_in_dir_to_chromadb(docs_path, doc_extension):\n",
    "    # Process each file in the docs_path directory\n",
    "    for file in os.listdir(docs_path):\n",
    "        if file.endswith(doc_extension):\n",
    "            file_path = os.path.join(docs_path, file)\n",
    "\n",
    "            print(f\"Processing {file_path} file.\")\n",
    "\n",
    "            with open(file_path) as f:\n",
    "                try:\n",
    "                    documents_list = []\n",
    "                    ids_list = []\n",
    "                    metadatas_list = []\n",
    "                    embeddings_list = []\n",
    "\n",
    "                    file_contents = f.read()\n",
    "\n",
    "                    file_chunks = text_splitter.split_text(file_contents)\n",
    "\n",
    "                    for i, file_chunk in enumerate(file_chunks):\n",
    "                        documents_list.append(file_chunk)\n",
    "                        ids_list.append(f\"{file}_{i}\")\n",
    "                        metadatas_list.append({\"source\": file, \"chunk_id\": i})\n",
    "                        # INGEST TO VECTOR STORE\n",
    "                        doc_vectors = embeddings_fn_by_hf.embed_query(file_chunk)\n",
    "                        embeddings_list.append(doc_vectors)\n",
    "\n",
    "                    # Ingest the documents into the vector store\n",
    "                    __vs_resp = write_to_vec_store_collection(\n",
    "                        DB_PATH,\n",
    "                        COLLECTION_NAME,\n",
    "                        documents_list,\n",
    "                        ids_list,\n",
    "                        embeddings_list,\n",
    "                        metadatas_list,\n",
    "                    )\n",
    "\n",
    "                    if not __vs_resp:\n",
    "                        raise Exception(f\"Error occurred while processing {file} file.\")\n",
    "\n",
    "                    print(f\"file: {file} added to vector store.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error occurred while processing {file} file.\")\n",
    "                    print(str(e))\n",
    "                    raise e\n",
    "\n",
    "    print(f\"{len(os.listdir(docs_path))} files added to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_docs_in_dir_to_chromadb(RAW_DATA_PATH, \".md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Database from disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB Heartbeat: 1705849036209515100\n",
      "ChromaDB Collections: [Collection(name=fn_markdown)]\n",
      "ChromaDB has 4585 documents\n"
     ]
    }
   ],
   "source": [
    "vs_chroma_client = chromadb.PersistentClient(path=DB_PATH)\n",
    "docs_collection = vs_chroma_client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME)\n",
    "\n",
    "print(f\"ChromaDB Heartbeat: {vs_chroma_client.heartbeat()}\")\n",
    "print(f\"ChromaDB Collections: {vs_chroma_client.list_collections()}\")\n",
    "\n",
    "\n",
    "# Verify ChromaDB is setup correctly, by checking document count\n",
    "print(f\"ChromaDB has {docs_collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the data was inserted by looking at the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadatas</th>\n",
       "      <th>documents</th>\n",
       "      <th>uris</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add-bindings-existing-function.md_0</td>\n",
       "      <td>[-0.04316641017794609, -0.11902757734060287, -...</td>\n",
       "      <td>{'chunk_id': 0, 'source': 'add-bindings-existi...</td>\n",
       "      <td>---\\ntitle: Connect functions to other Azure s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add-bindings-existing-function.md_1</td>\n",
       "      <td>[-0.008143081329762936, -0.0859667956829071, -...</td>\n",
       "      <td>{'chunk_id': 1, 'source': 'add-bindings-existi...</td>\n",
       "      <td>## Local development       \\n\\nWhen you develo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add-bindings-existing-function.md_2</td>\n",
       "      <td>[-0.03155401349067688, -0.048116981983184814, ...</td>\n",
       "      <td>{'chunk_id': 2, 'source': 'add-bindings-existi...</td>\n",
       "      <td>### Manually add bindings based on examples\\n\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ids  \\\n",
       "0  add-bindings-existing-function.md_0   \n",
       "1  add-bindings-existing-function.md_1   \n",
       "2  add-bindings-existing-function.md_2   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [-0.04316641017794609, -0.11902757734060287, -...   \n",
       "1  [-0.008143081329762936, -0.0859667956829071, -...   \n",
       "2  [-0.03155401349067688, -0.048116981983184814, ...   \n",
       "\n",
       "                                           metadatas  \\\n",
       "0  {'chunk_id': 0, 'source': 'add-bindings-existi...   \n",
       "1  {'chunk_id': 1, 'source': 'add-bindings-existi...   \n",
       "2  {'chunk_id': 2, 'source': 'add-bindings-existi...   \n",
       "\n",
       "                                           documents  uris  data  \n",
       "0  ---\\ntitle: Connect functions to other Azure s...  None  None  \n",
       "1  ## Local development       \\n\\nWhen you develo...  None  None  \n",
       "2  ### Manually add bindings based on examples\\n\\...  None  None  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# docs_collection.peek(2)\n",
    "pd.DataFrame(docs_collection.peek(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for text matching the query string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_txt(query, docs_collection):\n",
    "    passage = docs_collection.query(query_texts=[query], n_results=1)[\n",
    "        \"documents\"][0][0]\n",
    "    return passage\n",
    "\n",
    "\n",
    "def get_relevant_docs(query, docs_collection):\n",
    "    docs = docs_collection.query(\n",
    "        query_texts=[query], n_results=5, include=[\"documents\"]\n",
    "    )\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Text: ---\n",
      "title: Guidance for developing Azure Functions\n",
      "description: Learn the Azure Functions concepts and techniques that you need to develop functions in Azure, across all programming languages and bindings.\n",
      "ms.assetid: d8efe41a-bef8-4167-ba97-f3e016fcd39e\n",
      "ms.topic: conceptual\n",
      "ms.date: 09/06/2023\n",
      "ms.custom: ignite-2022, devx-track-extended-java, devx-track-js, devx-track-python\n",
      "zone_pivot_groups: programming-languages-set-functions\n",
      "---\n",
      "\n",
      "# Azure Functions developer guide\n",
      "\n",
      "In Azure Functions, all functions share some core technical concepts and components, regardless of your preferred language or development environment. This article is language-specific. Choose your preferred language at the top of the article.\n",
      "\n",
      "This article assumes that you've already read the [Azure Functions overview](functions-overview.md).\n"
     ]
    }
   ],
   "source": [
    "# Perform embedding search\n",
    "usr_query_1 = \"How to configure Azure Functions with a virtual network\"\n",
    "usr_query = \"What are Azure Functions\"\n",
    "\n",
    "matching_txt = get_relevant_txt(usr_query, docs_collection)\n",
    "\n",
    "print(f\"Matching Text: {matching_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found: 5\n",
      "\u001b[31mUser Input:What are Azure Functions\u001b[0m\n",
      "---\n",
      "title: Guidance for developing Azure Functions\n",
      "description: Learn the Azure Functions concepts and techniques that you need to develop functions in Azure, across all programming languages and bindings.\n",
      "ms.assetid: d8efe41a-bef8-4167-ba97-f3e016fcd39e\n",
      "ms.topic: conceptual\n",
      "ms.date: 09/06/2023\n",
      "ms.custom: ignite-2022, devx-track-extended-java, devx-track-js, devx-track-python\n",
      "zone_pivot_groups: programming-languages-set-functions\n",
      "---\n",
      "\n",
      "# Azure Functions developer guide\n",
      "\n",
      "In Azure Functions, all functions share some core technical concepts and components, regardless of your preferred language or development environment. This article is language-specific. Choose your preferred language at the top of the article.\n",
      "\n",
      "This article assumes that you've already read the [Azure Functions overview](functions-overview.md).\n",
      "\u001b[32m+++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "---\n",
      "title: Azure Functions Scenarios \n",
      "description: Identify key scenarios that use Azure Functions to provide serverless compute resources in aa Azure cloud-based topology. \n",
      "ms.topic: conceptual\n",
      "ms.custom: devx-track-extended-java, devx-track-js, devx-track-python\n",
      "ms.date: 05/15/2023\n",
      "zone_pivot_groups: programming-languages-set-functions-lang-workers\n",
      "---\n",
      "\n",
      "# Azure Functions scenarios\n",
      "\n",
      "We often build systems to react to a series of critical events. Whether you're building a web API, responding to database changes, processing event streams or messages, Azure Functions can be used to implement them.\n",
      "\n",
      "In many cases, a function [integrates with an array of cloud services](functions-triggers-bindings.md) to provide feature-rich implementations. The following are a common (but by no means exhaustive) set of scenarios for Azure Functions.\n",
      "\n",
      "Select your development language at the top of the article.\n",
      "\n",
      "## Process file uploads\n",
      "\u001b[32m+++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "---\n",
      "title: Azure Functions Overview \n",
      "description: Learn how you can use Azure Functions to build robust serverless apps.\n",
      "ms.assetid: 01d6ca9f-ca3f-44fa-b0b9-7ffee115acd4\n",
      "ms.topic: overview\n",
      "ms.date: 05/22/2023\n",
      "ms.custom: contperf-fy21q2, devdivchpfy22, ignite-2022, build-2023\n",
      "zone_pivot_groups: programming-languages-set-functions-lang-workers\n",
      "---\n",
      "\n",
      "# Azure Functions overview\n",
      "\n",
      "Azure Functions is a serverless solution that allows you to write less code, maintain less infrastructure, and save on costs. Instead of worrying about deploying and maintaining servers, the cloud infrastructure provides all the up-to-date resources needed to keep your applications running.\n",
      "\n",
      "You focus on the code that matters most to you, in the most productive language for you, and Azure Functions handles the rest.\n",
      "\n",
      "For the best experience with the Functions documentation, choose your preferred development language from the list of native Functions languages at the top of the article.\n",
      "\n",
      "## Scenarios\n",
      "\u001b[32m+++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "## Code project\n",
      "\n",
      "At the core of Azure Functions is a language-specific code project that implements one or more units of code execution called _functions_. Functions are simply methods that run in the Azure cloud based on events, in response to HTTP requests, or on a schedule. Think of your Azure Functions code project as a mechanism for organizing, deploying, and collectively managing your individual functions in the project when they're running in Azure. For more information, see [Organize your functions](functions-best-practices.md#organize-your-functions).\n",
      "\u001b[32m+++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "# Develop Azure Functions by using Visual Studio Code\n",
      "\n",
      "The [Azure Functions extension for Visual Studio Code] lets you locally develop functions and deploy them to Azure. If this experience is your first with Azure Functions, you can learn more at [An introduction to Azure Functions](functions-overview.md).\n",
      "\n",
      "The Azure Functions extension provides these benefits:\n",
      "\n",
      "* Edit, build, and run functions on your local development computer.\n",
      "* Publish your Azure Functions project directly to Azure.\n",
      "* Write your functions in various languages while taking advantage of the benefits of Visual Studio Code.\n",
      "\u001b[32m+++++++++++++++++++++++++++++++++++\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "matching_docs = get_relevant_docs(usr_query, docs_collection)\n",
    "\n",
    "print(f\"Total docs found: {len(matching_docs['documents'][0])}\")\n",
    "\n",
    "print(\"\\033[31m\" + \"User Input:\" + usr_query + \"\\033[0m\")\n",
    "\n",
    "\n",
    "for result in matching_docs[\"documents\"]:\n",
    "    for i in result:\n",
    "        print(i)\n",
    "        print(\"\\033[32m\" + \"+++++++++++++++++++++++++++++++++++\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prompt to pass to GPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Azure OpenAI Client & Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "\n",
    "def embeddings_generator_az_oai(text, model=\"nice\"):\n",
    "    # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if Azure OpenAI Embeddings are generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 16:01:12,762 - httpx - INFO - HTTP Request: POST https://eastus.api.cognitive.microsoft.com//openai/deployments/nice/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated embeddings\n"
     ]
    }
   ],
   "source": [
    "sample_txt_embeddings = embeddings_generator_az_oai(\n",
    "    \"Welcome to Miztiikal World\",\n",
    "    # model should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "    model=embeddings_deployment_name,\n",
    ")\n",
    "\n",
    "if sample_txt_embeddings is None:\n",
    "    print(\"No embeddings found\")\n",
    "else:\n",
    "    print(f\"Successfully generated embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps to ground the model with prompts and system instructions.\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "def generate_completion(usr_query, r_data, num_tokens=2000):\n",
    "    system_prompt = \"\"\"You are an intelligent assistant for Microsoft Azure services.\n",
    "    Use the following pieces of context to answer the question at the end. Question is enclosed in <question></question>.\n",
    "    Do keep the following things in mind when answering the question:\n",
    "        - If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "        - Keep the answer as concise as possible.\n",
    "        - Use only the context to answer the question. Context is enclosed in <context></context>\n",
    "        - The context contains one or more paragraph of text that is formatted as markdown. When answering, remove the sentences from the markdown that contain markdown links.\n",
    "        - If the answer is not found in context, simply output \"I'm sorry but I do not know the answer to your question. Please visit Microsoft Learn (https://learn.microsoft.com) or ask a question on StackOverflow (https://stackoverflow.com/questions/tagged/azure).\n",
    "        - Do not include the code in output unless the question is asked to produce the code.\n",
    "        \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": usr_query},\n",
    "        {\"role\": \"assistant\", \"content\": r_data},\n",
    "    ]\n",
    "\n",
    "    # print(\"\\033[32m----------------------------------------------\\033[0m\")\n",
    "    # print(f\"{messages}\")\n",
    "    # print(\"\\033[32m----------------------------------------------\\033[0m\")\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=completions_deployment_name,\n",
    "        messages=messages,\n",
    "        # max_tokens=num_tokens,\n",
    "        temperature=0,\n",
    "        stop=\"+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n\",\n",
    "    )\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 16:01:29,362 - httpx - INFO - HTTP Request: POST https://eastus.api.cognitive.microsoft.com//openai/deployments/hellno/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Query: \u001b[32m What are Azure Functions \u001b[0m\n",
      "Response: \u001b[36m Azure Functions is a serverless computing service provided by Microsoft Azure. It allows developers to write and deploy small pieces of code, called functions, that can be triggered by events such as HTTP requests, database changes, or scheduled timers. Azure Functions abstracts away the underlying infrastructure, allowing developers to focus on writing the code that matters most to them. Functions can be written in various programming languages and can integrate with other Azure services to provide feature-rich implementations. \u001b[0m\n",
      "total_tokens: \u001b[36m 1126 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "matching_docs = get_relevant_docs(usr_query, docs_collection)\n",
    "\n",
    "matching_docs_str = \"\".join(matching_docs[\"documents\"][0])\n",
    "\n",
    "resp = generate_completion(usr_query, matching_docs_str)\n",
    "\n",
    "print(f\"User_Query: \\033[32m {usr_query} \\033[0m\")\n",
    "print(f\"Response: \\033[36m { resp.choices[0].message.content} \\033[0m\")\n",
    "print(f\"total_tokens: \\033[36m { resp.usage.total_tokens} \\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 16:02:21,464 - httpx - INFO - HTTP Request: POST https://eastus.api.cognitive.microsoft.com//openai/deployments/hellno/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Query: \u001b[32m trigger blob to functions \u001b[0m\n",
      "Assistant: \u001b[36m To trigger a function when a new or updated blob is detected in Azure Blob storage, you can use the Blob storage trigger in Azure Functions. This trigger starts a function whenever a blob is added or updated in a specified container. The blob contents can be provided as input to the function.\n",
      "\n",
      "Here is an example of how to use the Blob storage trigger in Python:\n",
      "\n",
      "```python\n",
      "import logging\n",
      "import azure.functions as func\n",
      "\n",
      "@app.blob_trigger(name=\"BlobTrigger\", path=\"container-name/{blobname}\", connection=\"AzureWebJobsStorage\")\n",
      "def process_blob(myblob: func.InputStream):\n",
      "    logging.info(f\"Blob trigger function processed blob \\n\"\n",
      "                 f\"Name: {myblob.name}\\n\"\n",
      "                 f\"Blob Size: {myblob.length} bytes\")\n",
      "```\n",
      "\n",
      "In this example, the `@app.blob_trigger` decorator is used to define the function as a blob trigger. The `name` parameter specifies the name of the function, the `path` parameter specifies the path pattern for the blobs to trigger the function, and the `connection` parameter specifies the connection string for the Azure Storage account.\n",
      "\n",
      "You can customize the function code inside the `process_blob` function to perform any desired processing on the blob.\n",
      "\n",
      "Please note that this example is specific to Python. If you are using a different programming language, the syntax may vary slightly. \u001b[0m\n",
      "total_tokens: \u001b[36m 1361 \u001b[0m\n",
      "\u001b[32mHow can I help you? - Type 'stop' when you are done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "usr_query = input(\"Prompt: \")\n",
    "\n",
    "\n",
    "while usr_query.lower() not in [\"end\", \"quit\", \"exit\", \"stop\"]:\n",
    "    if usr_query.lower() == \"stop\":\n",
    "        break\n",
    "\n",
    "    matching_docs = get_relevant_docs(usr_query, docs_collection)\n",
    "\n",
    "    print(f\"Total docs found: {len(matching_docs['documents'][0])}\")\n",
    "\n",
    "    matching_docs_str = \"\".join(matching_docs[\"documents\"][0])\n",
    "\n",
    "    # print(\"\\033[32m----------------------------------------------\\033[0m\")\n",
    "    # print(f\"{matching_docs}\")\n",
    "    # print(\"\\033[32m----------------------------------------------\\033[0m\")\n",
    "\n",
    "    resp = generate_completion(usr_query, matching_docs_str)\n",
    "\n",
    "    assistant_response = resp.choices[0].message.content\n",
    "\n",
    "    print(f\"total_tokens: \\033[36m { resp.usage.total_tokens} \\033[0m\")\n",
    "    print(f\"User_Query: \\033[32m {usr_query} \\033[0m\")\n",
    "    print(f\"Assistant: \\033[36m { assistant_response} \\033[0m\")\n",
    "\n",
    "    print(\n",
    "        \"\\033[32m\" + \"How can I help you? - Type 'stop' when you are done.\" + \"\\033[0m\"\n",
    "    )\n",
    "\n",
    "    usr_query = input(\"Question: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT NEXT LINE TO SKIP THIS CELL EXECUTION\n",
    "# %%script skipping --no-raise-error\n",
    "\n",
    "\n",
    "# To cleanup, you can delete the collection\n",
    "\n",
    "vs_chroma_client.delete_collection()\n",
    "\n",
    "vs_chroma_client.persist()\n",
    "\n",
    "\n",
    "# Or just nuke the persist directory\n",
    "\n",
    "# rm -rf data/processed/dbs/azure_docs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
